import cv2
import mediapipe as mp
import pyautogui
import numpy as np
import time

mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)
mp_drawing = mp.solutions.drawing_utils
screen_width, screen_height = pyautogui.size()

def select_camera():
    for i in range(5):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            print(f"Camera {i} detected.")
            return i
    print("No camera found.")
    exit()

camera_index = select_camera()
cap = cv2.VideoCapture(camera_index)

smooth_buffer = []
BUFFER_SIZE = 5
click_timer = None
hold_duration = 2.0
is_dragging = False
initial_drag_position = None

def calculate_cursor_position(landmarks):
    finger_tip = landmarks[8]
    thumb_tip = landmarks[4]
    x = int(finger_tip.x * screen_width)
    y = int(finger_tip.y * screen_height)
    smooth_buffer.append((x, y))
    if len(smooth_buffer) > BUFFER_SIZE:
        smooth_buffer.pop(0)
    avg_x = int(np.mean([pos[0] for pos in smooth_buffer]))
    avg_y = int(np.mean([pos[1] for pos in smooth_buffer]))
    return avg_x, avg_y

def is_thumb_and_index_close(landmarks, threshold=0.05):
    thumb_tip = landmarks[4]
    index_tip = landmarks[8]
    distance = np.sqrt((thumb_tip.x - index_tip.x) ** 2 + (thumb_tip.y - index_tip.y) ** 2)
    return distance < threshold

def handle_click_and_drag(cursor_position, thumb_and_index_close):
    global click_timer, is_dragging, initial_drag_position
    if thumb_and_index_close:
        if click_timer is None:
            click_timer = time.time()
        elif time.time() - click_timer >= hold_duration:
            if not is_dragging:
                pyautogui.doubleClick()
                is_dragging = True
                initial_drag_position = cursor_position
                pyautogui.mouseDown()
            else:
                pyautogui.moveTo(*cursor_position, duration=0.1)
    else:
        if is_dragging:
            is_dragging = False
            pyautogui.mouseUp()
        click_timer = None

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    frame = cv2.flip(frame, 1)
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(rgb_frame)
    
    if results.multi_hand_landmarks:
        hand_landmarks = results.multi_hand_landmarks[0]
        mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
        x, y = calculate_cursor_position(hand_landmarks.landmark)
        pyautogui.moveTo(x, y, duration=0.1)
        thumb_and_index_close = is_thumb_and_index_close(hand_landmarks.landmark)
        handle_click_and_drag((x, y), thumb_and_index_close)

    cv2.imshow('Advanced Gesture Control', frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
